{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAEt9MUtFVnp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, LSTM,GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lgYOQoAGUuc"
   },
   "outputs": [],
   "source": [
    "# load the IMDB dataset\n",
    "\n",
    "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nldHRGggG2ly",
    "outputId": "9b1c8e4d-7916-4294-9dea-2950956d3ffe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUzmIKl_HEQo",
    "outputId": "2711e346-7029-40e4-dbb7-2625afbc13b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTRuqgcOHICG"
   },
   "outputs": [],
   "source": [
    "X_train=pad_sequences(X_train,maxlen=100)\n",
    "\n",
    "#By default this is going to perform the pre-padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nlp6O3DQHW8y",
    "outputId": "a973f82a-5aec-420b-ec6d-4032fef1ab1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1415,   33,    6, ...,   19,  178,   32],\n",
       "       [ 163,   11, 3215, ...,   16,  145,   95],\n",
       "       [1301,    4, 1873, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [  11,    6, 4065, ...,    4, 3586,    2],\n",
       "       [ 100, 2198,    8, ...,   12,    9,   23],\n",
       "       [  78, 1099,   17, ...,  204,  131,    9]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPi5w_zXLLLO",
    "outputId": "c062a9e8-598b-4a56-f83f-cede24a99b4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1415,   33,    6,   22,   12,  215,   28,   77,   52,    5,   14,\n",
       "        407,   16,   82,    2,    8,    4,  107,  117, 5952,   15,  256,\n",
       "          4,    2,    7, 3766,    5,  723,   36,   71,   43,  530,  476,\n",
       "         26,  400,  317,   46,    7,    4,    2, 1029,   13,  104,   88,\n",
       "          4,  381,   15,  297,   98,   32, 2071,   56,   26,  141,    6,\n",
       "        194, 7486,   18,    4,  226,   22,   21,  134,  476,   26,  480,\n",
       "          5,  144,   30, 5535,   18,   51,   36,   28,  224,   92,   25,\n",
       "        104,    4,  226,   65,   16,   38, 1334,   88,   12,   16,  283,\n",
       "          5,   16, 4472,  113,  103,   32,   15,   16, 5345,   19,  178,\n",
       "         32], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhkwPUTvLO8z",
    "outputId": "c0ae2166-791e-45b4-b3e3-f40cd0fffd14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAvooh5qHYKc"
   },
   "outputs": [],
   "source": [
    "X_test=pad_sequences(X_test,maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wj3Fk98tHk0Z",
    "outputId": "28b1f8f2-fbb4-4f62-d0c2-d674dd88a0dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   14,    6,  717],\n",
       "       [   6,  976, 2078, ...,  125,    4, 3077],\n",
       "       [   4, 5673,    7, ...,    9,   57,  975],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   21,  846, 5518],\n",
       "       [   0,    1,   11, ..., 2302,    7,  470],\n",
       "       [  56,   96,  346, ...,   34, 2005, 2643]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a86TpAMdHmU4"
   },
   "outputs": [],
   "source": [
    "#define the model for Deep Simple RNN\n",
    "\n",
    "#by setting return_sequences=True we are enabling respective hidden states\n",
    "#to pass the output in the same sequence to the next hidden layer\n",
    "#VVImp: See this image \"explaining_return_sequence=True.png\" for the\n",
    "#       better understanding\n",
    "\n",
    "##See LSTM_Demo.ipynb file in Lec4 folder to understand the below parameters\n",
    "\n",
    "##One way to create a sequential model is by adding new layers using model.add()-->check LSTM_Demo.ipynb\n",
    "##Or another way is by using below method where we are goining to mention the different sequential layers under\n",
    "##a comma separataed list\n",
    "\n",
    "model=Sequential([\n",
    "           Embedding(10000,32,input_length=100), #embedding layer to convert word into vectors--> Input layer\n",
    "           SimpleRNN(5,return_sequences=True),# RNN layer1 with five units or neurons\n",
    "           SimpleRNN(5),#this is Rnn layer2 with five units or neurons\n",
    "           Dense(1,activation=\"sigmoid\")#outputlayer for the binary claasificaiton\n",
    "           ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VVV Important\n",
    "Go through this https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "to understand the dimension of the embedding layer\n",
    "\n",
    "Please note that 10000 represents the vocab size. Numbers present in each enocoded or embedded vector will be under the range 10000 representing the numeric postion of the respective word in the encoded vector.\n",
    "\n",
    "Please note that in this example each word of a sentence is embedded in 32 vector size. Since in each sentence we are having 100 words so, we are getting 100X32 matrix as an output of this embedding layer. Not sure how the number of parameters are getting calculated for Embedding layer.\n",
    "\n",
    "# Encoding Vs Embedding:\n",
    "Both are used to convert the non-numeric or categorical data into numbers since models (ML/DL based) understands numbers. Key difference is in NLP task we need to extract the sementic and context of the data as well(like how similar two words are) which is acheived by representing the vector in higger space called vector embedding space achieved by embedding and not by encoding. Enbedding is fine in traditional classification use case and not for the use case where order, sementic, sequence of the non numeric or categorical data matters\n",
    "\n",
    "Read this beautiful blog and observe the key differences b/w Encoding and Embedding, use cases where they are used etc:\n",
    "https://www.linkedin.com/pulse/understanding-differences-between-encoding-embedding-mba-ms-phd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7KtdOtPOJQLP",
    "outputId": "80a9026a-6d0d-4b89-ee3b-91cba3db976a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "##Ignore the error. Need to run the pervious cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFKah0YiJSyg"
   },
   "outputs": [],
   "source": [
    "# defining the model Deep LSTM\n",
    "\n",
    "model= Sequential([\n",
    "    Embedding(10000,32,input_length=100),\n",
    "    LSTM(5,return_sequences=True),  #Observe the output dimension in the model.summary()\n",
    "    LSTM(5),   #Observe the output dimension in the model.summary()\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0qFvrYZfNfgj",
    "outputId": "c972c1ef-0926-47cc-a266-c6a7cd346add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 100, 32)           320000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 5)            760       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 5)                 220       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320986 (1.22 MB)\n",
      "Trainable params: 320986 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "##Observe when return_sequences=True then we are getting 100X5 representing 100 words of\n",
    "##a sentence furture passed or compressed through 5 LSTM cells\n",
    "\n",
    "##Whereas, in other case LSTM(5) by default return_sequences=False hence we don't need to\n",
    "##maintain the sequence hence 100 representing the words in a sentence is no more needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vy715KRdNnDm"
   },
   "outputs": [],
   "source": [
    "# defining the model for deep GRU\n",
    "\n",
    "\n",
    "l= Sequential([\n",
    "    Embedding(10000,32,input_length=100),\n",
    "    GRU(5,return_sequences=True),\n",
    "    GRU(5),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DK-qiOSwODFm",
    "outputId": "c3c39077-aff7-40a5-b1f1-b587e86eb351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 100, 32)           320000    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 100, 5)            585       \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 5)                 180       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320771 (1.22 MB)\n",
      "Trainable params: 320771 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZ6Y8SEaOE_C"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5I9LUy7_OUHg",
    "outputId": "1114f0da-7e11-4133-92e0-1e0bd6aded16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 42s 54ms/step - loss: 0.5093 - accuracy: 0.7440 - val_loss: 0.4157 - val_accuracy: 0.8180\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 11s 18ms/step - loss: 0.3066 - accuracy: 0.8781 - val_loss: 0.3681 - val_accuracy: 0.8416\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 0.2297 - accuracy: 0.9165 - val_loss: 0.3799 - val_accuracy: 0.8430\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 9s 15ms/step - loss: 0.1805 - accuracy: 0.9391 - val_loss: 0.4179 - val_accuracy: 0.8380\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 0.1394 - accuracy: 0.9553 - val_loss: 0.4515 - val_accuracy: 0.8324\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "##After this we can perform the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-directional RNN and LSTM and GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAgolXFDOaDJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Bidirectional, SimpleRNN, LSTM,GRU,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOF80FzRPWoT",
    "outputId": "4de0816b-5d79-428d-be63-f7aa6f753355"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1415,   33,    6, ...,   19,  178,   32],\n",
       "       [ 163,   11, 3215, ...,   16,  145,   95],\n",
       "       [1301,    4, 1873, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [  11,    6, 4065, ...,    4, 3586,    2],\n",
       "       [ 100, 2198,    8, ...,   12,    9,   23],\n",
       "       [  78, 1099,   17, ...,  204,  131,    9]], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "#This has been already padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6NbDRR6PZpK",
    "outputId": "1c435a3b-c22c-4192-c062-1b517f47c1a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   14,    6,  717],\n",
       "       [   6,  976, 2078, ...,  125,    4, 3077],\n",
       "       [   4, 5673,    7, ...,    9,   57,  975],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   21,  846, 5518],\n",
       "       [   0,    1,   11, ..., 2302,    7,  470],\n",
       "       [  56,   96,  346, ...,   34, 2005, 2643]], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpFYSKx8PcY6"
   },
   "outputs": [],
   "source": [
    "maxlen=100\n",
    "embedding_dim=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hVmCeTeP31V"
   },
   "outputs": [],
   "source": [
    "##This is the simple uni-directional RNN\n",
    "\n",
    "model=Sequential([\n",
    "           Embedding(10000,32,input_length=100), #embedding later to convcer word into vectors\n",
    "           SimpleRNN(5,return_sequences=False),# RNN layer with five units\n",
    "           Dense(1,activation=\"sigmoid\")#outputlayer for the binary claasificaiton\n",
    "           ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIpcsvGXQWm_",
    "outputId": "214c09da-6c4f-4f02-aebc-7351d002ed9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 100, 32)           320000    \n",
      "                                                                 \n",
      " simple_rnn_6 (SimpleRNN)    (None, 100, 5)            190       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100, 1)            6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320196 (1.22 MB)\n",
      "Trainable params: 320196 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9ZT0fYgQdSw"
   },
   "outputs": [],
   "source": [
    "#We will be simply using Bidirectional wrapper to convert the respective\n",
    "#unidirectional RNN/LSTM/GRU into corresponding Bidirectional architecture\n",
    "\n",
    "\n",
    "model2=Sequential([\n",
    "           Embedding(10000,32,input_length=100), #embedding later to convcer word into vectors\n",
    "           Bidirectional(SimpleRNN(5,return_sequences=False)),# RNN layer with five units\n",
    "           Dense(1,activation=\"sigmoid\")#outputlayer for the binary claasificaiton\n",
    "           ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2SZGkN9Qy0b",
    "outputId": "302e602b-0552-45ca-a3eb-cf9d80712bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 100, 32)           320000    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 10)                380       \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320391 (1.22 MB)\n",
      "Trainable params: 320391 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vNLWvl0Q170",
    "outputId": "d9b93aec-fec7-4266-9757-58cd9d252a1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "190+190\n",
    "\n",
    "#So Simple RNN layer represented in unidirectional or simple RNN\n",
    "#was having only 192 params. So with this logic is bi-directional\n",
    "#architecture we are going to have double parms that is\n",
    "#192+192=380"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6daIs8_Q57t"
   },
   "source": [
    "# your task is\n",
    "\n",
    "pos tagging, ner recognition. This can be easily done using nltk library. Already explored this while solving the placement assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
