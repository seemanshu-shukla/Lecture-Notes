{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FAETZSdb5XIS",
    "outputId": "868a497b-1844-42ba-a0ac-9db16c1dc6a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                          Version\n",
      "-------------------------------- ---------------------\n",
      "absl-py                          1.4.0\n",
      "aiohttp                          3.8.6\n",
      "aiosignal                        1.3.1\n",
      "alabaster                        0.7.13\n",
      "albumentations                   1.3.1\n",
      "altair                           4.2.2\n",
      "anyio                            3.7.1\n",
      "appdirs                          1.4.4\n",
      "argon2-cffi                      23.1.0\n",
      "argon2-cffi-bindings             21.2.0\n",
      "array-record                     0.5.0\n",
      "arviz                            0.15.1\n",
      "astropy                          5.3.4\n",
      "astunparse                       1.6.3\n",
      "async-timeout                    4.0.3\n",
      "atpublic                         4.0\n",
      "attrs                            23.1.0\n",
      "audioread                        3.0.1\n",
      "autograd                         1.6.2\n",
      "Babel                            2.13.1\n",
      "backcall                         0.2.0\n",
      "beautifulsoup4                   4.11.2\n",
      "bidict                           0.22.1\n",
      "bigframes                        0.13.0\n",
      "bleach                           6.1.0\n",
      "blinker                          1.4\n",
      "blis                             0.7.11\n",
      "blosc2                           2.0.0\n",
      "bokeh                            3.3.1\n",
      "bqplot                           0.12.42\n",
      "branca                           0.7.0\n",
      "build                            1.0.3\n",
      "CacheControl                     0.13.1\n",
      "cachetools                       5.3.2\n",
      "catalogue                        2.0.10\n",
      "certifi                          2023.7.22\n",
      "cffi                             1.16.0\n",
      "chardet                          5.2.0\n",
      "charset-normalizer               3.3.2\n",
      "chex                             0.1.7\n",
      "click                            8.1.7\n",
      "click-plugins                    1.1.1\n",
      "cligj                            0.7.2\n",
      "cloudpickle                      2.2.1\n",
      "cmake                            3.27.7\n",
      "cmdstanpy                        1.2.0\n",
      "colorcet                         3.0.1\n",
      "colorlover                       0.3.0\n",
      "colour                           0.1.5\n",
      "community                        1.0.0b1\n",
      "confection                       0.1.3\n",
      "cons                             0.4.6\n",
      "contextlib2                      21.6.0\n",
      "contourpy                        1.2.0\n",
      "cryptography                     41.0.5\n",
      "cufflinks                        0.17.3\n",
      "cupy-cuda11x                     11.0.0\n",
      "cvxopt                           1.3.2\n",
      "cvxpy                            1.3.2\n",
      "cycler                           0.12.1\n",
      "cymem                            2.0.8\n",
      "Cython                           3.0.5\n",
      "dask                             2023.8.1\n",
      "datascience                      0.17.6\n",
      "db-dtypes                        1.1.1\n",
      "dbus-python                      1.2.18\n",
      "debugpy                          1.6.6\n",
      "decorator                        4.4.2\n",
      "defusedxml                       0.7.1\n",
      "diskcache                        5.6.3\n",
      "distributed                      2023.8.1\n",
      "distro                           1.7.0\n",
      "dlib                             19.24.2\n",
      "dm-tree                          0.1.8\n",
      "docutils                         0.18.1\n",
      "dopamine-rl                      4.0.6\n",
      "duckdb                           0.9.2\n",
      "earthengine-api                  0.1.379\n",
      "easydict                         1.11\n",
      "ecos                             2.0.12\n",
      "editdistance                     0.6.2\n",
      "eerepr                           0.0.4\n",
      "en-core-web-sm                   3.6.0\n",
      "entrypoints                      0.4\n",
      "et-xmlfile                       1.1.0\n",
      "etils                            1.5.2\n",
      "etuples                          0.3.9\n",
      "exceptiongroup                   1.1.3\n",
      "fastai                           2.7.13\n",
      "fastcore                         1.5.29\n",
      "fastdownload                     0.0.7\n",
      "fastjsonschema                   2.19.0\n",
      "fastprogress                     1.0.3\n",
      "fastrlock                        0.8.2\n",
      "filelock                         3.13.1\n",
      "fiona                            1.9.5\n",
      "firebase-admin                   5.3.0\n",
      "Flask                            2.2.5\n",
      "flatbuffers                      23.5.26\n",
      "flax                             0.7.5\n",
      "folium                           0.14.0\n",
      "fonttools                        4.44.3\n",
      "frozendict                       2.3.8\n",
      "frozenlist                       1.4.0\n",
      "fsspec                           2023.6.0\n",
      "future                           0.18.3\n",
      "gast                             0.5.4\n",
      "gcsfs                            2023.6.0\n",
      "GDAL                             3.4.3\n",
      "gdown                            4.6.6\n",
      "geemap                           0.28.2\n",
      "gensim                           4.3.2\n",
      "geocoder                         1.38.1\n",
      "geographiclib                    2.0\n",
      "geopandas                        0.13.2\n",
      "geopy                            2.3.0\n",
      "gin-config                       0.5.0\n",
      "glob2                            0.7\n",
      "google                           2.0.3\n",
      "google-ai-generativelanguage     0.3.3\n",
      "google-api-core                  2.11.1\n",
      "google-api-python-client         2.84.0\n",
      "google-auth                      2.17.3\n",
      "google-auth-httplib2             0.1.1\n",
      "google-auth-oauthlib             1.0.0\n",
      "google-cloud-bigquery            3.12.0\n",
      "google-cloud-bigquery-connection 1.12.1\n",
      "google-cloud-bigquery-storage    2.22.0\n",
      "google-cloud-core                2.3.3\n",
      "google-cloud-datastore           2.15.2\n",
      "google-cloud-firestore           2.11.1\n",
      "google-cloud-functions           1.13.3\n",
      "google-cloud-iam                 2.12.2\n",
      "google-cloud-language            2.9.1\n",
      "google-cloud-resource-manager    1.10.4\n",
      "google-cloud-storage             2.8.0\n",
      "google-cloud-translate           3.11.3\n",
      "google-colab                     1.0.0\n",
      "google-crc32c                    1.5.0\n",
      "google-generativeai              0.2.2\n",
      "google-pasta                     0.2.0\n",
      "google-resumable-media           2.6.0\n",
      "googleapis-common-protos         1.61.0\n",
      "googledrivedownloader            0.4\n",
      "graphviz                         0.20.1\n",
      "greenlet                         3.0.1\n",
      "grpc-google-iam-v1               0.12.7\n",
      "grpcio                           1.59.2\n",
      "grpcio-status                    1.48.2\n",
      "gspread                          3.4.2\n",
      "gspread-dataframe                3.3.1\n",
      "gym                              0.25.2\n",
      "gym-notices                      0.0.8\n",
      "h5netcdf                         1.3.0\n",
      "h5py                             3.9.0\n",
      "holidays                         0.36\n",
      "holoviews                        1.17.1\n",
      "html5lib                         1.1\n",
      "httpimport                       1.3.1\n",
      "httplib2                         0.22.0\n",
      "huggingface-hub                  0.19.4\n",
      "humanize                         4.7.0\n",
      "hyperopt                         0.2.7\n",
      "ibis-framework                   6.2.0\n",
      "idna                             3.4\n",
      "imageio                          2.31.6\n",
      "imageio-ffmpeg                   0.4.9\n",
      "imagesize                        1.4.1\n",
      "imbalanced-learn                 0.10.1\n",
      "imgaug                           0.4.0\n",
      "importlib-metadata               6.8.0\n",
      "importlib-resources              6.1.1\n",
      "imutils                          0.5.4\n",
      "inflect                          7.0.0\n",
      "iniconfig                        2.0.0\n",
      "install                          1.3.5\n",
      "intel-openmp                     2023.2.0\n",
      "ipyevents                        2.0.2\n",
      "ipyfilechooser                   0.6.0\n",
      "ipykernel                        5.5.6\n",
      "ipyleaflet                       0.17.4\n",
      "ipython                          7.34.0\n",
      "ipython-genutils                 0.2.0\n",
      "ipython-sql                      0.5.0\n",
      "ipytree                          0.2.2\n",
      "ipywidgets                       7.7.1\n",
      "itsdangerous                     2.1.2\n",
      "jax                              0.4.20\n",
      "jaxlib                           0.4.20+cuda11.cudnn86\n",
      "jeepney                          0.7.1\n",
      "jieba                            0.42.1\n",
      "Jinja2                           3.1.2\n",
      "joblib                           1.3.2\n",
      "jsonpickle                       3.0.2\n",
      "jsonschema                       4.19.2\n",
      "jsonschema-specifications        2023.11.1\n",
      "jupyter-client                   6.1.12\n",
      "jupyter-console                  6.1.0\n",
      "jupyter_core                     5.5.0\n",
      "jupyter-server                   1.24.0\n",
      "jupyterlab-pygments              0.2.2\n",
      "jupyterlab-widgets               3.0.9\n",
      "kaggle                           1.5.16\n",
      "keras                            2.14.0\n",
      "keyring                          23.5.0\n",
      "kiwisolver                       1.4.5\n",
      "langcodes                        3.3.0\n",
      "launchpadlib                     1.10.16\n",
      "lazr.restfulclient               0.14.4\n",
      "lazr.uri                         1.0.6\n",
      "lazy_loader                      0.3\n",
      "libclang                         16.0.6\n",
      "librosa                          0.10.1\n",
      "lida                             0.0.10\n",
      "lightgbm                         4.1.0\n",
      "linkify-it-py                    2.0.2\n",
      "llmx                             0.0.15a0\n",
      "llvmlite                         0.41.1\n",
      "locket                           1.0.0\n",
      "logical-unification              0.4.6\n",
      "lxml                             4.9.3\n",
      "malloy                           2023.1064\n",
      "Markdown                         3.5.1\n",
      "markdown-it-py                   3.0.0\n",
      "MarkupSafe                       2.1.3\n",
      "matplotlib                       3.7.1\n",
      "matplotlib-inline                0.1.6\n",
      "matplotlib-venn                  0.11.9\n",
      "mdit-py-plugins                  0.4.0\n",
      "mdurl                            0.1.2\n",
      "miniKanren                       1.0.3\n",
      "missingno                        0.5.2\n",
      "mistune                          0.8.4\n",
      "mizani                           0.9.3\n",
      "mkl                              2023.2.0\n",
      "ml-dtypes                        0.2.0\n",
      "mlxtend                          0.22.0\n",
      "more-itertools                   10.1.0\n",
      "moviepy                          1.0.3\n",
      "mpmath                           1.3.0\n",
      "msgpack                          1.0.7\n",
      "multidict                        6.0.4\n",
      "multipledispatch                 1.0.0\n",
      "multitasking                     0.0.11\n",
      "murmurhash                       1.0.10\n",
      "music21                          9.1.0\n",
      "natsort                          8.4.0\n",
      "nbclassic                        1.0.0\n",
      "nbclient                         0.9.0\n",
      "nbconvert                        6.5.4\n",
      "nbformat                         5.9.2\n",
      "nest-asyncio                     1.5.8\n",
      "networkx                         3.2.1\n",
      "nibabel                          4.0.2\n",
      "nltk                             3.8.1\n",
      "notebook                         6.5.5\n",
      "notebook_shim                    0.2.3\n",
      "numba                            0.58.1\n",
      "numexpr                          2.8.7\n",
      "numpy                            1.23.5\n",
      "oauth2client                     4.1.3\n",
      "oauthlib                         3.2.2\n",
      "opencv-contrib-python            4.8.0.76\n",
      "opencv-python                    4.8.0.76\n",
      "opencv-python-headless           4.8.1.78\n",
      "openpyxl                         3.1.2\n",
      "opt-einsum                       3.3.0\n",
      "optax                            0.1.7\n",
      "orbax-checkpoint                 0.4.2\n",
      "osqp                             0.6.2.post8\n",
      "packaging                        23.2\n",
      "pandas                           1.5.3\n",
      "pandas-datareader                0.10.0\n",
      "pandas-gbq                       0.17.9\n",
      "pandas-stubs                     1.5.3.230304\n",
      "pandocfilters                    1.5.0\n",
      "panel                            1.3.1\n",
      "param                            2.0.1\n",
      "parso                            0.8.3\n",
      "parsy                            2.1\n",
      "partd                            1.4.1\n",
      "pathlib                          1.0.1\n",
      "pathy                            0.10.3\n",
      "patsy                            0.5.3\n",
      "peewee                           3.17.0\n",
      "pexpect                          4.8.0\n",
      "pickleshare                      0.7.5\n",
      "Pillow                           9.4.0\n",
      "pip                              23.1.2\n",
      "pip-tools                        6.13.0\n",
      "platformdirs                     4.0.0\n",
      "plotly                           5.15.0\n",
      "plotnine                         0.12.4\n",
      "pluggy                           1.3.0\n",
      "polars                           0.17.3\n",
      "pooch                            1.8.0\n",
      "portpicker                       1.5.2\n",
      "prefetch-generator               1.0.3\n",
      "preshed                          3.0.9\n",
      "prettytable                      3.9.0\n",
      "proglog                          0.1.10\n",
      "progressbar2                     4.2.0\n",
      "prometheus-client                0.18.0\n",
      "promise                          2.3\n",
      "prompt-toolkit                   3.0.41\n",
      "prophet                          1.1.5\n",
      "proto-plus                       1.22.3\n",
      "protobuf                         3.20.3\n",
      "psutil                           5.9.5\n",
      "psycopg2                         2.9.9\n",
      "ptyprocess                       0.7.0\n",
      "py-cpuinfo                       9.0.0\n",
      "py4j                             0.10.9.7\n",
      "pyarrow                          9.0.0\n",
      "pyasn1                           0.5.0\n",
      "pyasn1-modules                   0.3.0\n",
      "pycocotools                      2.0.7\n",
      "pycparser                        2.21\n",
      "pyct                             0.5.0\n",
      "pydantic                         1.10.13\n",
      "pydata-google-auth               1.8.2\n",
      "pydot                            1.4.2\n",
      "pydot-ng                         2.0.0\n",
      "pydotplus                        2.0.2\n",
      "PyDrive                          1.3.1\n",
      "PyDrive2                         1.6.3\n",
      "pyerfa                           2.0.1.1\n",
      "pygame                           2.5.2\n",
      "Pygments                         2.16.1\n",
      "PyGObject                        3.42.1\n",
      "PyJWT                            2.3.0\n",
      "pymc                             5.7.2\n",
      "pymystem3                        0.2.0\n",
      "PyOpenGL                         3.1.7\n",
      "pyOpenSSL                        23.3.0\n",
      "pyparsing                        3.1.1\n",
      "pyperclip                        1.8.2\n",
      "pyproj                           3.6.1\n",
      "pyproject_hooks                  1.0.0\n",
      "pyshp                            2.3.1\n",
      "PySocks                          1.7.1\n",
      "pytensor                         2.14.2\n",
      "pytest                           7.4.3\n",
      "python-apt                       0.0.0\n",
      "python-box                       7.1.1\n",
      "python-dateutil                  2.8.2\n",
      "python-louvain                   0.16\n",
      "python-slugify                   8.0.1\n",
      "python-utils                     3.8.1\n",
      "pytz                             2023.3.post1\n",
      "pyviz_comms                      3.0.0\n",
      "PyWavelets                       1.4.1\n",
      "PyYAML                           6.0.1\n",
      "pyzmq                            23.2.1\n",
      "qdldl                            0.1.7.post0\n",
      "qudida                           0.0.4\n",
      "ratelim                          0.1.6\n",
      "referencing                      0.31.0\n",
      "regex                            2023.6.3\n",
      "requests                         2.31.0\n",
      "requests-oauthlib                1.3.1\n",
      "requirements-parser              0.5.0\n",
      "rich                             13.7.0\n",
      "rpds-py                          0.13.0\n",
      "rpy2                             3.4.2\n",
      "rsa                              4.9\n",
      "safetensors                      0.4.0\n",
      "scikit-image                     0.19.3\n",
      "scikit-learn                     1.2.2\n",
      "scipy                            1.11.3\n",
      "scooby                           0.9.2\n",
      "scs                              3.2.4\n",
      "seaborn                          0.12.2\n",
      "SecretStorage                    3.3.1\n",
      "Send2Trash                       1.8.2\n",
      "setuptools                       67.7.2\n",
      "shapely                          2.0.2\n",
      "six                              1.16.0\n",
      "sklearn-pandas                   2.2.0\n",
      "smart-open                       6.4.0\n",
      "sniffio                          1.3.0\n",
      "snowballstemmer                  2.2.0\n",
      "sortedcontainers                 2.4.0\n",
      "soundfile                        0.12.1\n",
      "soupsieve                        2.5\n",
      "soxr                             0.3.7\n",
      "spacy                            3.6.1\n",
      "spacy-legacy                     3.0.12\n",
      "spacy-loggers                    1.0.5\n",
      "Sphinx                           5.0.2\n",
      "sphinxcontrib-applehelp          1.0.7\n",
      "sphinxcontrib-devhelp            1.0.5\n",
      "sphinxcontrib-htmlhelp           2.0.4\n",
      "sphinxcontrib-jsmath             1.0.1\n",
      "sphinxcontrib-qthelp             1.0.6\n",
      "sphinxcontrib-serializinghtml    1.1.9\n",
      "SQLAlchemy                       2.0.23\n",
      "sqlglot                          17.16.2\n",
      "sqlparse                         0.4.4\n",
      "srsly                            2.4.8\n",
      "stanio                           0.3.0\n",
      "statsmodels                      0.14.0\n",
      "sympy                            1.12\n",
      "tables                           3.8.0\n",
      "tabulate                         0.9.0\n",
      "tbb                              2021.11.0\n",
      "tblib                            3.0.0\n",
      "tenacity                         8.2.3\n",
      "tensorboard                      2.14.1\n",
      "tensorboard-data-server          0.7.2\n",
      "tensorflow                       2.14.0\n",
      "tensorflow-datasets              4.9.3\n",
      "tensorflow-estimator             2.14.0\n",
      "tensorflow-gcs-config            2.14.0\n",
      "tensorflow-hub                   0.15.0\n",
      "tensorflow-io-gcs-filesystem     0.34.0\n",
      "tensorflow-metadata              1.14.0\n",
      "tensorflow-probability           0.22.0\n",
      "tensorstore                      0.1.45\n",
      "termcolor                        2.3.0\n",
      "terminado                        0.18.0\n",
      "text-unidecode                   1.3\n",
      "textblob                         0.17.1\n",
      "tf-slim                          1.1.0\n",
      "thinc                            8.1.12\n",
      "threadpoolctl                    3.2.0\n",
      "tifffile                         2023.9.26\n",
      "tinycss2                         1.2.1\n",
      "tokenizers                       0.15.0\n",
      "toml                             0.10.2\n",
      "tomli                            2.0.1\n",
      "toolz                            0.12.0\n",
      "torch                            2.1.0+cu118\n",
      "torchaudio                       2.1.0+cu118\n",
      "torchdata                        0.7.0\n",
      "torchsummary                     1.5.1\n",
      "torchtext                        0.16.0\n",
      "torchvision                      0.16.0+cu118\n",
      "tornado                          6.3.2\n",
      "tqdm                             4.66.1\n",
      "traitlets                        5.7.1\n",
      "traittypes                       0.2.1\n",
      "transformers                     4.35.2\n",
      "triton                           2.1.0\n",
      "tweepy                           4.14.0\n",
      "typer                            0.9.0\n",
      "types-pytz                       2023.3.1.1\n",
      "types-setuptools                 68.2.0.1\n",
      "typing_extensions                4.5.0\n",
      "tzlocal                          5.2\n",
      "uc-micro-py                      1.0.2\n",
      "uritemplate                      4.1.1\n",
      "urllib3                          2.0.7\n",
      "vega-datasets                    0.9.0\n",
      "wadllib                          1.3.6\n",
      "wasabi                           1.1.2\n",
      "wcwidth                          0.2.10\n",
      "webcolors                        1.13\n",
      "webencodings                     0.5.1\n",
      "websocket-client                 1.6.4\n",
      "Werkzeug                         3.0.1\n",
      "wheel                            0.41.3\n",
      "widgetsnbextension               3.6.6\n",
      "wordcloud                        1.9.2\n",
      "wrapt                            1.14.1\n",
      "xarray                           2023.7.0\n",
      "xarray-einstats                  0.6.0\n",
      "xgboost                          2.0.2\n",
      "xlrd                             2.0.1\n",
      "xxhash                           3.4.1\n",
      "xyzservices                      2023.10.1\n",
      "yarl                             1.9.2\n",
      "yellowbrick                      1.5\n",
      "yfinance                         0.2.31\n",
      "zict                             3.0.0\n",
      "zipp                             3.17.0\n"
     ]
    }
   ],
   "source": [
    "# We will be using Keras pythonic library for this implementation. So using below cmd we are verifying the same\n",
    "\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZLF6QPmH6_m"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential  #Sequential used to create the Neural Network based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnywlBgrIJ5M"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-U8RH5YIR1G"
   },
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bHz1-IpIWcI"
   },
   "outputs": [],
   "source": [
    "model.add(SimpleRNN(4,input_shape=(4,5)))\n",
    "#(4->Number of hidden layers, input_shape=(4->number of words in lengthiest sentence,5->Vocabulary))\n",
    "#For exmaple if we have 3 sentence[movie was good, movie was bad, movie was not bad] so since 3rd sentence is lengthiest one\n",
    "#with word count 4 we will use 4 as number of rows while defining the input_shape. While doing that for sentence 1 and 2\n",
    "#(having word count=3) automatic padding of the 4th word will happen internally which probably will be encoded as \n",
    "#[0,0,0,0,0] representing no word\n",
    "\n",
    "##Please note that above we have defined the hidden layer and using input_shape have define the input layer\n",
    "##Also in above by default the activation function being used for the hidden layer neurons is tanh\n",
    "\n",
    "model.add(Dense(1, activation=\"sigmoid\")) #Here we have defined the Output layer with Sigmoid activation function\n",
    "                                          #being used for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HtgLSSSJgNe",
    "outputId": "1044fb33-ceb2-4743-f585-59d5aefc4eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 4)                 40        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45 (180.00 Byte)\n",
      "Trainable params: 45 (180.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#VVImp\n",
    "\n",
    "model.summary()\n",
    "\n",
    "##Number of neurons at input layer = Vocabulary size\n",
    "##We have 4 words in a sentence (where 2 sentences were padded to 4 length as explained above). So 4 timestamp is required \n",
    "##to pass a sentence and generated predicted output. When it goes to next word there is a reset and again same chain goes on\n",
    "##Or in other words feeback is going to terminate only when all the words a sentence is completely processed through RNN\n",
    "\n",
    "##Trainable params = 5*4+4 +  4*4 +   4*1+1 = \n",
    "##                    I/P    Hidden  O/P   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zeAiZEfJkPt",
    "outputId": "015d051a-4671-4f67-b5f9-fd6573c93143",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.6955212 ,  0.7785003 , -0.07227027, -0.69514155],\n",
       "        [-0.14051485,  0.78357303,  0.79060864, -0.26040286],\n",
       "        [-0.16312689, -0.8125834 , -0.21167338,  0.58308876],\n",
       "        [ 0.34405172, -0.22713137, -0.7825148 , -0.13567638],\n",
       "        [-0.1023249 ,  0.6525897 , -0.53951585,  0.7725153 ]],\n",
       "       dtype=float32),\n",
       " array([[ 0.4514761 , -0.7264177 , -0.4277959 , -0.29236478],\n",
       "        [-0.8617577 , -0.5050725 , -0.04722452, -0.00672787],\n",
       "        [-0.21230304,  0.40662986, -0.3590341 , -0.8128186 ],\n",
       "        [ 0.0920344 , -0.22775255,  0.8281636 , -0.5037891 ]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.25142407],\n",
       "        [ 0.8916596 ],\n",
       "        [ 0.4443779 ],\n",
       "        [-0.7056412 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()\n",
    "\n",
    "##These are internally assigned weights. each array represents a weight/bias. Below we are getting 5 weights/bias.\n",
    "##lets decode each of them:\n",
    "\n",
    "##model.get_weights()[0] and model.get_weights()[1] are decoded in the below cells\n",
    "\n",
    "#model.get_weights()[2] or array([0., 0., 0., 0.], dtype=float32), represents the bias for the b/w I/P and hidden layer\n",
    "##Note that bias is not need in feedback loop only weight is required there\n",
    "\n",
    "##model.get_weights()[3], represents the weights b/w hidden and output layer\n",
    "\n",
    "##model.get_weights()[4] or rray([0.] represents the bias b/w hidden and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqLYRTRRLHIt",
    "outputId": "bea36869-14fb-4c00-e0c9-d5b9d606c54a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6955212 ,  0.7785003 , -0.07227027, -0.69514155],\n",
       "       [-0.14051485,  0.78357303,  0.79060864, -0.26040286],\n",
       "       [-0.16312689, -0.8125834 , -0.21167338,  0.58308876],\n",
       "       [ 0.34405172, -0.22713137, -0.7825148 , -0.13567638],\n",
       "       [-0.1023249 ,  0.6525897 , -0.53951585,  0.7725153 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[0]  ##These are the connecting weights b/w I/P and hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OfDkk8YLNvN",
    "outputId": "15241efb-34c0-4b7c-f2f5-1c4649b7b7c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[0].shape #We have 5 neurons in I/P and 4 hidden neurons that why above we can see we have 20 possible\n",
    "                             #weights in the first section of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sy0ExpSLW3f",
    "outputId": "04d2b53e-a66a-40f1-9abc-b09c0935a002"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4514761 , -0.7264177 , -0.4277959 , -0.29236478],\n",
       "       [-0.8617577 , -0.5050725 , -0.04722452, -0.00672787],\n",
       "       [-0.21230304,  0.40662986, -0.3590341 , -0.8128186 ],\n",
       "       [ 0.0920344 , -0.22775255,  0.8281636 , -0.5037891 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[1]  ##This section represents the feedback loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_YuiEbYLaKP",
    "outputId": "439bd0a3-d70c-4464-a62c-0544fec91406"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[1].shape  #There are 4 hidden neurons and each passes output to each other which is govered through\n",
    "                              #some trainable weights. That's why we are having 20 possible weight combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DinIQTJFLjVk"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb \n",
    "#We are going to use this inbuilt dataset which is judges the sentiment of reviews for movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ijdY-1dUcd3"
   },
   "outputs": [],
   "source": [
    "\n",
    "(X_train,y_train),(X_test,y_test)=imdb.load_data()\n",
    "    \n",
    "##If we are going to print imdb.load_data() then we will find out that this is already an encoded dataset which is in tuple\n",
    "##form. So, order to unpack this tuple dataset we are writing like this which is set format from keras side\n",
    "# (X_train,y_train),(X_test,y_test) format and in tuple form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nh7IppgXVP0_",
    "outputId": "3ca43abf-3908-48fa-a22f-5da34b523fd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])  ##representing that there are 218 words which are already encoded in the first review in train split\n",
    "\n",
    "#To view this simply use print(X_train[0])\n",
    "#Please note embedding here used doesn't seem like one hot encoding. Instead it's some different encoding is used which\n",
    "#is done using keras tokenizer(google it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfE1BxGUY3v2",
    "outputId": "7a430923-c683-4868-c7b6-7b26306297d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[1])  ##representing that there are 189 words which are already encoded in the second review in train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uERut-9VY6Dm",
    "outputId": "1e97f6a9-5a39-4f72-981f-9b1d960ea201"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQDaq8zQZJTN",
    "outputId": "cb95f33c-ccda-4737-cb97-cd7d497e385d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist=[]\n",
    "for review in X_train:\n",
    "  mylist.append(len(review))\n",
    "min(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJZNpnA_Vi42",
    "outputId": "7b64e6e5-a4a1-49a0-c0c6-6a3a51d903dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape   #Representing that there are 25000 training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TWGKi5itVree",
    "outputId": "ff8ea88c-3dbc-49d9-89bf-70d6a7a5b3e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape    #Representing that there are 25000 test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twGrOr-5VvSU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sent=[\n",
    "\n",
    "      \"india won worldcup\",\n",
    "      \"rohit played very well\",\n",
    "      \"above all is my imagination\",\n",
    "      \"bharat mata ki jay\",\n",
    "      \"definatly we goona win next worldcup\"\n",
    "]  ##In case sentences are untokenized or unembedded words, then by using kereas tokenizer we will first tokenize them.\n",
    "  ##In imdb dataset this was already done, that's why took this example to explain how tokenisation be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dCrzjMBWhOO",
    "outputId": "7c9be909-1094-431c-ab2a-60d4918a3fee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india won worldcup',\n",
       " 'rohit played very well',\n",
       " 'above all is my imagination',\n",
       " 'bharat mata ki jay',\n",
       " 'definatly we goona win next worldcup']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5YdkdbyWjN4"
   },
   "outputs": [],
   "source": [
    "# it is performing integer encoding\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bva5kFfyWwbs"
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFjuDkL_Wz8e"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jeHFSgr5W6ad",
    "outputId": "82addfea-b605-40e9-e136-ae1c8be247c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'worldcup': 1,\n",
       " 'india': 2,\n",
       " 'won': 3,\n",
       " 'rohit': 4,\n",
       " 'played': 5,\n",
       " 'very': 6,\n",
       " 'well': 7,\n",
       " 'above': 8,\n",
       " 'all': 9,\n",
       " 'is': 10,\n",
       " 'my': 11,\n",
       " 'imagination': 12,\n",
       " 'bharat': 13,\n",
       " 'mata': 14,\n",
       " 'ki': 15,\n",
       " 'jay': 16,\n",
       " 'definatly': 17,\n",
       " 'we': 18,\n",
       " 'goona': 19,\n",
       " 'win': 20,\n",
       " 'next': 21}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UTZEMUgqXABK",
    "outputId": "70ab5741-fa82-4a50-ccaa-f446c7451184"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('india', 1),\n",
       "             ('won', 1),\n",
       "             ('worldcup', 2),\n",
       "             ('rohit', 1),\n",
       "             ('played', 1),\n",
       "             ('very', 1),\n",
       "             ('well', 1),\n",
       "             ('above', 1),\n",
       "             ('all', 1),\n",
       "             ('is', 1),\n",
       "             ('my', 1),\n",
       "             ('imagination', 1),\n",
       "             ('bharat', 1),\n",
       "             ('mata', 1),\n",
       "             ('ki', 1),\n",
       "             ('jay', 1),\n",
       "             ('definatly', 1),\n",
       "             ('we', 1),\n",
       "             ('goona', 1),\n",
       "             ('win', 1),\n",
       "             ('next', 1)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dNujhOEnXHDv",
    "outputId": "750b094e-4f3a-45ad-b079-9da4f22bd044"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count  ##Document_count represents the number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PF-7C9sXToK"
   },
   "outputs": [],
   "source": [
    "encoding=tokenizer.texts_to_sequences(sent)   ##self explanatory from the execution of the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cvA7VQOXbyW",
    "outputId": "37562a0b-77c3-4aee-e77a-6141007ed259"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 1],\n",
       " [4, 5, 6, 7],\n",
       " [8, 9, 10, 11, 12],\n",
       " [13, 14, 15, 16],\n",
       " [17, 18, 19, 20, 21, 1]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lj_A_i8EXnbw"
   },
   "outputs": [],
   "source": [
    "##In above we can see that that each encoded document or sentence is of different length which we have to convert into same\n",
    "##length. That's we are we are using padding by importing following pyhtonic library\n",
    "\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FmExqhJfX3tP",
    "outputId": "8ba12c4f-6207-4c39-87b3-6d1f8d88ded8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  1,  0,  0,  0],\n",
       "       [ 4,  5,  6,  7,  0,  0],\n",
       "       [ 8,  9, 10, 11, 12,  0],\n",
       "       [13, 14, 15, 16,  0,  0],\n",
       "       [17, 18, 19, 20, 21,  1]], dtype=int32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pad_sequences(encoding ,padding=\"post\")\n",
    "\n",
    "##By default padding is set to \"pre\" which will do the pre padding whereas 0s will appear at the begning.\n",
    "#But we want them to appear at end that why padding is set to \"post\"\n",
    "\n",
    "##Also, we can observe that here by default padding is done according to the length of longest sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYrl3YLsX6dY",
    "outputId": "1d186132-3d67-4334-9980-f15c7d7b98f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UejoY5VfYaBI",
    "outputId": "27c402b8-9835-44ec-c236-0b24e93da7bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7AO-Jp7ZmAe"
   },
   "outputs": [],
   "source": [
    "##VVImp\n",
    "\n",
    "##Why doing padding here. So we learned that by default padding is done according to the lengthiest word. But in real time\n",
    "##scenario that can be many words in the lenthiest sentence say for example len(X_train[0]) is 218. So if we start padding\n",
    "##words upto max length 218 then it would be very much computational expensive.\n",
    "\n",
    "##So in such a case we can go with the padding equivalent to the length of the sentence having smallest word count.\n",
    "##In above cell (17th cell above starting from this cell) we have written a logic to capture the review with smallest word\n",
    "##count which is only 11. So here in this case if we taken max length padding as 11 then a lot of contenxual information\n",
    "##will get miss out. So that why we are taking maxlen padding somewhere in b/w that is 50. We might loss contexual\n",
    "##understanding but this will speed up the training process of our RNN model\n",
    "\n",
    "X_train=pad_sequences(X_train ,padding=\"post\",maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-x-xUDxZ3Kv"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test=pad_sequences(X_test ,padding=\"post\",maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Wo2rHzOYbcH"
   },
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52SSoMPjYf2n"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.add(SimpleRNN(32,input_shape=(50,1)))   #Decode this by own self as explained earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CZL2A_0aA8w"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HC2hi-Y-aHjG",
    "outputId": "1c67731f-8de1-4167-df38-58e7990a177c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_3 (SimpleRNN)    (None, 32)                1088      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1121 (4.38 KB)\n",
      "Trainable params: 1121 (4.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()\n",
    "\n",
    "##Decode the trainable params by own self as explained earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNI2qqAbaJle"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4yaEUGOaSJU",
    "outputId": "c51a96d7-692e-4707-e0b8-6930a9a68dd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 39s 42ms/step - loss: 0.6939 - accuracy: 0.5092 - val_loss: 0.6945 - val_accuracy: 0.5080\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.6932 - accuracy: 0.5061 - val_loss: 0.6939 - val_accuracy: 0.5069\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6942 - val_accuracy: 0.5024\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.6929 - accuracy: 0.5080 - val_loss: 0.6965 - val_accuracy: 0.5026\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 32s 42ms/step - loss: 0.6929 - accuracy: 0.5100 - val_loss: 0.6944 - val_accuracy: 0.5039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7d5b1bc32770>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILk_2KkFacME",
    "outputId": "2da5029a-7193-48c2-9d7a-d6924d92f5a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5120173],\n",
       "       [0.5120173],\n",
       "       [0.5120173],\n",
       "       ...,\n",
       "       [0.5120173],\n",
       "       [0.512018 ],\n",
       "       [0.5120173]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJS7BRiNbWQ4",
    "outputId": "9c1d6f52-420c-48e2-f75d-74d9465f7936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 7s 9ms/step - loss: 0.6944 - accuracy: 0.5039\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss,accuracy=model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTJpESRYbgeI",
    "outputId": "c5b4dc45-d48d-42ec-ee07-2f590c7226dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6943767070770264"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUgY7nQtbp29",
    "outputId": "4ba847a8-ca4a-47b1-9e4f-5e5a0452d65c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5038800239562988"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiBZhdRdbqf4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
